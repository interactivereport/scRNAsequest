[["index.html", "scRNASequest: an ecosystem of scRNA-seq analysis, visualization and publishing Chapter 1 Preface", " scRNASequest: an ecosystem of scRNA-seq analysis, visualization and publishing Kejie Li Biogen kejie.li@biogen.com Yu (Henry) Sun Biogen yuhenry.sun@biogen.com Zhengyu Ouyang BioInfoRx oyoung@bioinforx.com Soumya Negi Biogen soumya.negi@biogen.com Zhen Gao Biogen zhen.gao@biogen.com Jing Zhu Biogen jing.zhu@biogen.com Wanli Wang Biogen wanli.wang@biogen.com Yirui Chen Biogen yirui.chen@biogen.com Sarbottam Piya Biogen sarbottam.piya@biogen.com Wenxing Hu Biogen wenxing.hu@biogen.com Maria Zavodszky Biogen maria.zavodszky@biogen.com Hima Yalamanchili Biogen hima.yalamanchili@biogen.com Shaolong Cao Biogen shaolong.cao@biogen.com Andrew Gehrke Biogen andrew.gehrke@biogen.com Mark Sheehan Biogen make.sheehan@biogen.com Dann Huh Biogen dann.huh@biogen.com Fergal Casey Biogen fergal.casey@biogen.com Xinmin Zhang BioInfoRx xinmin@bioinforx.com Baohong Zhang (Corresponding Author) Biogen baohong.zhang@biogen.com These authors contribute equally Kejie Li, Yu (Henry) Sun, Zhengyu Ouyang 2023-07-14 Chapter 1 Preface This is a user manual written using Bookdown, which provides a detailed guide for scRNASequest. "],["introduction.html", "Chapter 2 Introduction", " Chapter 2 Introduction scRNASequest is a semi-automated single-cell RNA-seq (scRNA-seq) data analysis workflow which allows the following five different functionalities: Pre-processing from single-cell RNA sequencing UMI count matrix data (better generated with Cell Ranger) Applying multiple harmonization methods for batch correction Reference-dataset-based cell type label transfer and embedding projection Multi-sample multi-condition single-cell level differential gene expression analysis Seamless integration with cellxgene VIP for visualization and with CellDepot for data hosting and sharing by generating a compatible h5ad file. Users have the option to run it on a local laptop computer or interact with sge/slurm schedulers on high performance computing (HPC) clusters. This pipeline contains the following programs: scAnalyzer This is the main script in scRNASequest for single-cell data processing and analysis. Also, scAnalyzer is an all-in-one program for downstream data analysis, including pre-processing, batch correction, label transfer, differential gene expression analysis and CellDepot integration. Moreover, scAnalyzer is embedded with a Bookdown report generator, named scReport, which can produce a user-friendly, well-structured quality control report after each run. scDEG scDEG is a standalone pipeline for differential expression (DE) analysis using harmonized data. It has been embedded into the scAnalyzer pipeline. scRef scRef generates a reference dataset for label transfer. For each reference dataset, this program only needs to run once, and the reference h5ad file will be placed in a permanent path. sc2celldepot sc2celldepot offers a easy and fast way to convert your own RDS file or h5 results+cell annotation to Cellxgene VIP, without running the full pipeline. If you have run the full pipeline script (scAnalyzer), you should get the h5ad (UMI, embedding, etc.) and db (DE information) files for CellDepot publishing, and you won’t need to run sc2celldepot. scTool scTool provides flexibility for modifying the h5ad file, such as modifying annotation and extracting meta information. scRMambient scRMambient is a wrapper function to remove ambient RNAs using CellBender. A detailed comparison of the above scripts can be found below: Table 2.1: Pipeline scripts and their function Command Description Input Output scAnalyzer Main program to perform full scRNA-seq data anal-ysis with QC and data harmonization A path to analysis config file (config.yml) Final analysis results in h5ad and h5seurat format scDEG Program to perform DEG analysis between two phenotypes within each cluster of an annotation (such as cell types) A path to a DEG config file (config_DEG.yml) One DEG table for each cluster and an SQLite db file of all comparisons scRef Program to create Seurat ‘Azimuth’ references A path to a reference con-fig file (config_ref.yml) An RDS object with ‘Azi-muth’ reference for scAnalyzer sc2celldepot Program to transfer ana-lyzed data into h5ad for the cellxgene VIP (CellDepot) loading A path to a data config file (config_convert.yml) An h5ad file scTool Tool to add, remove or export express/annotation from an h5ad A path to an h5ad file A modified h5ad file or a csv file scRMambient Remove ambient RNA by the CellBender A path to a sample metadata file containing paths to raw (unfiltered) UMI along with a few Cell-Bender parameters CellBender filtered UMI counts in h5 format "],["installation.html", "Chapter 3 Installation 3.1 Install scRNASequest 3.2 Configure sys.yml file 3.3 Install cellxgene VIP 3.4 Install CellDepot", " Chapter 3 Installation 3.1 Install scRNASequest We provide two methods to install scRNASequest. The first one uses Conda, and the second one uses Docker. We have tested both methods on Linux servers; however, if you are a Mac user, please use the Docker method. 3.1.1 Installation using Conda First, please make sure you have Conda installed, or, Anaconda/Miniconda installed: which conda # Your conda path will be returned Then, we choose a directory and install scRNASequest by downloading the source code from GitHub. The directory you choose here will be the future directory of this pipeline. # Go to the directory you choose. This tutorial uses $HOME (~) directory as an example: cd ~ git clone https://github.com/interactivereport/scRNASequest.git cd scRNASequest # Install scRNASequest conda environment # Before running this, please make sure you have conda installed before # This step will take a while, usually between 30min to 1h depending on the internet speed # Thank you for your patience bash install.sh # The .env will be created under the src directory ls ~/scRNASequest/src/.env # Now the pipeline scripts under the scRNASequest folder can be used # Users can add the scRNASequest directory to the environment permanently # by editing ~/.bash_profile or ~/.bashrc vim ~/.bash_profile # Add the full path of the scRNASequest directory to $PATH. # In our example, this will be: ~/scRNASequest PATH=$PATH:~/scRNASequest # Close the vim text editor and source the file source ~/.bash_profile #To verify the installation, type the main program name, and the following message will show up: scAnalyzer #Output: ===== Please set the sys.yml in ~/scRNASequest. An example is &#39;~/scRNASequest/src/sys_example.yml&#39;. ===== You got the above message because the sys.yml file is missing under the pipeline src directory (in our case, ~/scRNASequest/src/). Please copy the sys_example.yml template there first: cp ~/scRNASequest/src/sys_example.yml ~/scRNASequest/src/sys.yml Then, fill in the following required items. These directories will be used to host final results (.h5ad files) of the pipeline as well as the reference files for cell type label transfer. Since we have cellxgenedir and ref directories created under the demo directory, we use them here: celldepotDir: ~/scRNASequest/demo/cellxgenedir. # the absolute path to the cellxgene VIP host folder, where the h5ad files will be copied to for cellxgene VIP refDir: ~/scRNASequest/demo/ref # the absolute path to the Seurat reference folder if building reference is desired You may fill in the cellxgene VIP server path after installing cellxgene VIP later, but this is not required for running the pipeline. We leave this empty here. celldepotHttp: # the cellxgene host (with --dataroot option) link http://HOST:PORT/d/ You may change the information in the sys.yml file later, following the full tutorial here. Then type the name of the main program, scAnalyzer again: ***** 2023-03-14 14:48:13 ***** ########### ## scRNAsequest: https://github.com/interactivereport/scRNAsequest.git ## Pipeline Path: /mnt/depts/dept04/compbio/projects/ndru_projects/Software/scRNAsequest ## Pipeline Date: 2023-03-01 10:10:55 -0500 ## git HEAD: d067bfd6dc056597d046a45f3b3b927dd122dd82 ########### scAnalyzer /path/to/a/DNAnexus/download/folder === or === scAnalyzer /path/to/a/config/file The config file will be generated automatically when a DNAnexus download folder is provided Available reference data: human_cortex: more information @ https://azimuth.hubmapconsortium.org/references/ If one of the above can be used as a reference for your datasets, please update the config file with the name in &#39;ref_name&#39;. Powered by None ------------ The installation was successful if you see the above message. Typing other scripts’ name, such as scRef, directly without any parameters will activate the user manual page: $ scRef ***** 2023-01-26 15:29:54 ***** ########### ## scRNAsequest: https://github.com/interactivereport/scRNAsequest.git ## Pipeline Path: /mnt/depts/dept04/compbio/edge_tools/scRNAsequest ## Pipeline Date: 2023-01-13 17:41:49 -0500 ## git HEAD: 3d463e0b127af499942b7adc2fc5af6ddfc6f11e ########### Loading resources scRef /path/to/a/output/folder === or === scRef /path/to/a/Ref/config/file The folder has to be existed. The Ref config file will be generated automatically when a path is provided ===== CAUTION ===== 1. This process will add a seurat reference data into the scRNAsequest pipeline PERMANENTLY! 2. Make sure the data provided for reference building is SCT transformed! Powered by the Research Data Sciences group [zhengyu.ouyang@biogen.com;kejie.li@biogen.com] ------------ Similary, you will also see the manual message printed out for other scripts: scDEG, sc2celldepot, and scTool. 3.1.2 Installation through Docker We provide a Docker image here: https://hub.docker.com/repository/docker/sunyumail93/scrnasequest/general. Users can pull this image to build a container, which has been tested on both Linux and Mac systems. This will take roughly 10 minutes to set up. We also provide a Dockerfile if you would like to build the image from scratch using the docker build command, which takes ~30 min. First, please make sure Docker has been installed and can be recognized through the command line: which docker # Your docker path will be returned Go to the directory you choose. This tutorial uses $HOME (~) directory as an example: cd ~ git clone https://github.com/interactivereport/scRNASequest.git cd scRNASequest Then we pull the docker image. This step takes ~10 min. docker pull sunyumail93/scrnasequest Initiate the docker container. This command uses -v to map the demo directory under scRNASequest to /demo in the container: docker run -v `pwd`/demo:/demo -d sunyumail93/scrnasequest The above command prepars for the demo run in 4. You can mount any directory containing your data to the Docker container using the syntax old_dir:container_dir. Verify your container: docker container ls #Results: CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4e0f3a40ce1d sunyumail93/scrnasequest &quot;/bin/sh -c &#39;while t…&quot; 54 seconds ago Up 52 seconds interesting_lewin The last column is the , and it will be used in the following steps. Now we launch the main program of this pipeline. In our example, is interesting_lewin. Please substitute to yours: docker exec -t -i &lt;container_name&gt; scAnalyzer #Output: ===== Please set the sys.yml in /home/scRNASequest/src. An example is &#39;/home/scRNASequest/src/sys_example.yml&#39;. ===== This is because the sys.yml configuration file is missing under the src directory. There is a sys.yml file prepared for running the demo data (see section 2.2), and you can copy it to the pipeline src directory using the command below. It will work for future analysis also. However, you may change the information in the sys.yml file later, following the full tutorial here. Please note that both ‘/demo/sys.yml’ and ‘/home/scRNASequest/src’ directories are in the container, rather than in your file system. docker exec -t -i &lt;container_name&gt; cp /demo/sys.yml /home/scRNASequest/src/ Now we run this command again, and we will see the pipeline message printed out, same as the one at the end of section 3.1.1: docker exec -t -i &lt;container_name&gt; scAnalyzer 3.2 Configure sys.yml file The sys.yml file contains critical information for the pipeline, which must be set up before running the pipeline. This file only needs to create once, under the src/ directory. You can use this sys_example.yml file as a template to prepare your file. The file name must be sys.yml and is located under the src/ directory of the pipeline. The first two rows are related to cellxgene VIP and CellDepot. The celldepotDir is required because all .h5ad files will be copied to this directory, and when launching cellxgene VIP, it will look for files in this directory. Please look into the tutorial below to learn how to set up cellxgene VIP. After setting up cellxgene VIP, you will know the HOST and PORT of your links, which can be included in celldepotHttp. The scAnalyzer pipeline won’t generate error if you don’t have celldepotHttp set up. In our demo dataset (demo/ directory under the pipeline folder), we provide the following information: celldepotDir: /demo/cellxgenedir # the absolute path to the cellxgene VIP host folder, where the h5ad files will be copied to for cellxgene VIP celldepotHttp: http://HOST:PORT/d/ # the cellxgene host (with --dataroot option) link http://HOST:PORT/d/ refDir: /demo/ref # the absolute path to the seurat refrence folder if building reference is desired minCell: 50 The refDir stores all Azimuth reference files for cell type label transfer. Please select a directory for this. The scRef pipeline will use this directory and copy all necessary files there. scRef will also modify this sys.yml file when new reference is added. An example of added reference is shown as: - human_cortex human_cortex: ref_file: https://zenodo.org/record/4546932/files/ref.Rds # local file absolute path can be provided as well ref_link: https://azimuth.hubmapconsortium.org/references/ ref_src: single nuclei ref_platform: SNARE-seq2 ref_assay: refAssay ref_neighbors: refdr.annoy.neighbors ref_reduction: refDR ref_reduction.model: refUMAP ref_label: - class - cluster - subclass - cross_species_cluster The powerby parameter sets the ending message after running the pipeline. An example would be: powerby: the Research Data Sciences Group at Biogen [zhengyu.ouyang@biogen.com;yuhenry.sun@biogen.com] # the message at the end An example of the message showing: Powered by the Research Data Sciences Group at Biogen [zhengyu.ouyang@biogen.com;yuhenry.sun@biogen.com] If you leave powerby as blank, it will show as: Powered by None. 3.3 Install cellxgene VIP The cellxgene VIP (Visualization In Plugin) platform can be used to visualize the h5ad file generated by the scRNASequest pipeline. This visualization step can be performed before the differential expression (DE) analysis to pinpoint meaningful clusters for downstream steps. If you include DE analysis when running scAnalyzer, you will also see DE results in Cellxgene VIP. Please follow the detailed instructions below to install cellxgene VIP: https://github.com/interactivereport/cellxgene_VIP After setting up, when launching cellxgene VIP, you will designate HOST name and PORT number. You can add this information in the sys.yml file as celldepotHttp under src/ directory. However, cellxgene VIP is not required for running any components of the scRNASequest pipeline (scAnalyzer, scRef, etc.). It is up to the user how to work with the h5ad files after running the scAnalyzer script, and (scanpy is an alternative option. 3.4 Install CellDepot If you have multiple projects, you will have to manage many cellxgene VIP links and related data files. CellDepot is a centralized database for storing single-cell/nucleus RNA-seq results. Please refer to the detailed instructions below to install CellDepot: https://celldepot.bxgenomics.com/celldepot_manual/install_environment.php The installation of CellDepot is optional if the user only needs to analyze the data, without publishing it into the CellDepot database. "],["demo-run.html", "Chapter 4 Demo run 4.1 Demo run with Conda 4.2 Demo run with Docker", " Chapter 4 Demo run We provide a demo dataset under the demo directory. This demo uses two snRNA-seq data from GSE185538 to run through the main steps, including QC, data integration (SCTransform, then Harmony), Seurat reference mapping, and evaluation of integration (kBET and silhouette). To save time, the differential expression analysis won’t be performed, and the DEGinfo.csv file is empty. This demo run contains two downsampled snRNA-seq data from the original study, and will take ~15-20 minutes to finish. Please note that to speed up the run, we used stringent QC cutoffs, which eliminated many cells. After running the scAnalyzer command, output files will be generated under the demo directory on your computer. Also, we provided config.yml, sampleMeta.csv and DEGinfo.csv files for running this demo so you can run the scAnalyzer command directly. Please note that these files are only for the demo run. Later for your own dataset, please follow the full tutorial in the next section, Data preparation, to generate the template of these files first. 4.1 Demo run with Conda Continuing from section 3.1.1, we assume that the pipeline was installed in: ~/scRNASequest. First, we set up the config file (~/scRNASequest/demo/config.yml) by pointing these parameters to your directory, and other lines don’t need to be changed: ... ref_name: ~/scRNASequest/demo/ref/rat_cortex_ref.rds # choose one from scAnalyzer call without argument output: ~/scRNASequest/demo # output path ... sample_meta: ~/scRNASequest/demo/sampleMeta.csv ... DEG_desp: ~/scRNASequest/demo/DEGinfo.csv # for DEG analysis. To save time, this demo run doesn&#39;t include DE analysis ... Accordingly, we modify the sampleMeta.csv file by providing the full path to .h5 files by adding ‘~/scRNASequest’: Sample_Name,h5path,Sex RatFemaleCigarette,~/scRNASequest/demo/data/RatFemaleCigarette.filtered_feature_bc_matrix.h5,Female RatMaleCigarette,~/scRNASequest/demo/data/RatMaleCigarette.filtered_feature_bc_matrix.h5,Male Then execute the following command: scAnalyzer ~/scRNASequest/demo/config.yml 4.2 Demo run with Docker After following section 3.1.2 to set up the pipeline, we are ready to run this demo: docker exec -t -i &lt;container_name&gt; scAnalyzer /demo/config.yml After running this demo, a list of files will be created: config.yml #Original config.yml file config.yml.20230314.log #Log file during pipeline run data/ #Original data files ├──RatFemaleCigarette.filtered_feature_bc_matrix.h5 ├──RatFemaleCigarette.metrics_summary.csv ├──RatMaleCigarette.filtered_feature_bc_matrix.h5 └──RatMaleCigarette.metrics_summary.csv DEGinfo.csv #Comparison file. In this demo, this is empty evaluation/ #Evaluation of harmonization ├──scRNASequest_demo_kBET_umap_k0_100.pdf └──scRNASequest_demo_Silhouette_boxplot_pc50.pdf log/ #Log files for each step ├──kBET.log ├──sctHarmony.log ├──SCT.log ├──SeuratRef.log └──ssilhouette.log QC/ #QC files ├──postfilter.QC.pdf ├──prefilter.QC.pdf ├──sequencingQC.csv └──sequencingQC.pdf raw/ #Original UMI counts, with and withour filtering ├──scRNASequest_demo.h5ad └──scRNASequest_demo_raw_prefilter.h5ad ref/ └──ref.Rds #Azimuth reference RSD file for cell type label transfer Rmarkdown/ #Pre-generated QC figures, for generating Bookdown report sampleMeta.csv #Input sample metainformation file scRNASequest_demo.h5ad #This is the final output h5ad file, and the expression values have been normalized cellxgene VIP will use this file for visualization scRNASequest_demo.h5seurat #Result in h5seurat format scRNASequest_demo_raw_added.h5ad #Since AnnData object can only have one count matrix, this one uses the raw UMI SCT/ #Results related to SCT transformation ├──scRNASequest_demo.cID ├──scRNASequest_demo.gID ├──scRNASequest_demo.h5 ├──scRNASequest_demo.h5ad ├──scRNASequest_demo.h5.rds └──scRNASequest_demo.scaleF sctHarmony/ #SCT+Harmony results ├──scRNASequest_demo.csv └──scRNASequest_demo.h5ad SeuratRef/ #Seurat reference mapping results ├──scRNASequest_demo.csv └──scRNASequest_demo.h5ad "],["data-preparation.html", "Chapter 5 Data preparation 5.1 Public data in h5 format 5.2 Public data in 10X MEX format 5.3 Self-prepared files", " Chapter 5 Data preparation scRNASequest pipeline is compatible with different single-cell experiment outputs, including the 10X MEX format and the 10X h5 format from Cell Ranger. The user may need to manually separate the annotation file, so that no cell filtering was performed. In this chapter, we will walk through how to prepare the data before running the pipeline. A bit more information about these two types of format: 10X MEX format: This format has three associated files: an mtx file and associated barcodes file as well as a features file. Based on the information provided by the 10X official website, the MEX is also called the Market Exchange (MEX) format, and the .mtx is a plain text file showing MatrixMarket matrix coordinates like this: %%MatrixMarket matrix coordinate integer general % 154 1 21 ... This means the gene in line 154 of the genes file, the 1st barcode in the barcodes file, has UMI counts=21. 10X h5 format: This format is a HDF5 format storing UMI count matrix, as described in the 10X official tutorial here. 5.1 Public data in h5 format Here, we first present an example of the data processing steps using a public EMBL EBI dataset: E-MTAB-11115. The nine processed zip files were downloaded and unzipped. There are total 6 data, with 6 corresponding *raw_feature_bc_matrix.h5 files. These files are required by the pipeline: #h5 matrix files -rwxrwxr--. 1 zouyang ngs 165M Oct 25 2021 5705STDY8058280.raw_feature_bc_matrix.h5 -rwxrwxr--. 1 zouyang ngs 165M Oct 25 2021 5705STDY8058281.raw_feature_bc_matrix.h5 -rwxrwxr--. 1 zouyang ngs 156M Oct 25 2021 5705STDY8058282.raw_feature_bc_matrix.h5 -rwxrwxr--. 1 zouyang ngs 162M Oct 25 2021 5705STDY8058283.raw_feature_bc_matrix.h5 -rwxrwxr--. 1 zouyang ngs 149M Oct 25 2021 5705STDY8058284.raw_feature_bc_matrix.h5 -rwxrwxr--. 1 zouyang ngs 177M Oct 25 2021 5705STDY8058285.raw_feature_bc_matrix.h5 This dataset also has cell type annotation files associated with each data. These files are optional to the pipeline, but if you would like to use their cell type labels, it would be better to include them in the sample meta file (See section 6.3). #Annotation files (optional to the pipeline) -rwxrwx---. 1 zouyang ngs 440K Apr 21 16:59 5705STDY8058280.annotation.csv -rwxrwx---. 1 zouyang ngs 446K Apr 21 16:59 5705STDY8058281.annotation.csv -rwxrwx---. 1 zouyang ngs 310K Apr 21 16:59 5705STDY8058282.annotation.csv -rwxrwx---. 1 zouyang ngs 282K Apr 21 16:59 5705STDY8058283.annotation.csv -rwxrwx---. 1 zouyang ngs 157K Apr 21 16:59 5705STDY8058284.annotation.csv -rwxrwx---. 1 zouyang ngs 555K Apr 21 16:59 5705STDY8058285.annotation.csv #A brief look at the annotation file: $ head -3 5705STDY8058280_annotation.csv Cell.ID,sample,annotation_1,annotation_1_print AAACCCAAGGAAGTAG-1,5705STDY8058280,Ext_L25,23_Ext_L25 AAACCCAAGGGCAGTT-1,5705STDY8058280,Ext_L56,24_Ext_L56 If SampleName.metrics_summary.csv files (QC files generated by Cell Ranger) are available, please also add them in the same directory as the h5 files, and the pipeline will use them to generate QC plots, but they are not required files of the pipeline. The expected file names should be: 5705STDY8058280.metrics_summary.csv 5705STDY8058281.metrics_summary.csv 5705STDY8058282.metrics_summary.csv 5705STDY8058283.metrics_summary.csv 5705STDY8058284.metrics_summary.csv 5705STDY8058285.metrics_summary.csv !!! Important Since we don’t provide the path of these metrics_summary.csv files to the pipeline, their prefix SampleName must be consistent with the Sample_Name column in the sample meta file (See section 5.2), so that the pipeline can recognize them automatically. You can certainly rename the files and the corresponding SampleName column if you would like to change the data names and how they appear in the final results. Also, for the metrics_summary.csv file names, the concatenator between the Sample_Name and “metrics_summary.csv” must be “.” so that the pipeline can read them automatically. This follows the naming criteria of Cell Ranger. 5.2 Public data in 10X MEX format Another popular format for single-cell RNA-seq is the MEX format. Here, we use a public dataset from NCBI/GEO: GSE185538 to walk through the procedures for pipeline setup. There are total 4 single-nucleus RNA-seq data, and all the processed data can be downloaded from the Supplementary file section as a tarball: GSE185538_RAW.tar: #Untar the file tar -xvf GSE185538_RAW.tar $ ls -l #Only show the MTX-related files -rw-rw-r-- 1 ysun4 compbio 97631 Sep 29 2021 GSM5617891_snRNA_FCtr_barcodes.tsv.gz -rw-rw-r-- 1 ysun4 compbio 206935 Sep 29 2021 GSM5617891_snRNA_FCtr_features.tsv.gz -rw-rw-r-- 1 ysun4 compbio 116235040 Sep 29 2021 GSM5617891_snRNA_FCtr_matrix.mtx.gz -rw-rw-r-- 1 ysun4 compbio 89425 Sep 29 2021 GSM5617892_snRNA_FEcig_barcodes.tsv.gz -rw-rw-r-- 1 ysun4 compbio 206935 Sep 29 2021 GSM5617892_snRNA_FEcig_features.tsv.gz -rw-rw-r-- 1 ysun4 compbio 101349173 Sep 29 2021 GSM5617892_snRNA_FEcig_matrix.mtx.gz -rw-rw-r-- 1 ysun4 compbio 283865 Sep 29 2021 GSM5617893_snRNA_MCtr_barcodes.tsv.gz -rw-rw-r-- 1 ysun4 compbio 206935 Sep 29 2021 GSM5617893_snRNA_MCtr_features.tsv.gz -rw-rw-r-- 1 ysun4 compbio 440019486 Sep 29 2021 GSM5617893_snRNA_MCtr_matrix.mtx.gz -rw-rw-r-- 1 ysun4 compbio 117119 Sep 29 2021 GSM5617894_snRNA_MEcig_barcodes.tsv.gz -rw-rw-r-- 1 ysun4 compbio 229853 Sep 29 2021 GSM5617894_snRNA_MEcig_features.tsv.gz -rw-rw-r-- 1 ysun4 compbio 159326641 Sep 29 2021 GSM5617894_snRNA_MEcig_matrix.mtx.gz Next, these files need to be organized into separate folders for the pipeline to read. In specific, we need to create separate folders for each data, and rename the three files to be: barcodes.tsv.gz, features.tsv.gz, and matrix.mtx.gz (Un-compressed files can also be used to run the pipeline, and the pipeline will compress them). The organized file hierarchy is below: GSE185538/ ├── GSM5617891_snRNA_FCtr ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ├── GSM5617892_snRNA_FEcig ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ├── GSM5617893_snRNA_MCtr ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz └── GSM5617894_snRNA_MEcig ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz 5.3 Self-prepared files If you have raw data in FASTQ format, please process them using the Cell Ranger pipeline to generate the raw_feature_bc_matrix.h5 and metrics_summary.csv files. Please visit Cell Ranger website here for more details about the outputs, in the “Output files” section. In short, Cell Ranger outputs filtered_feature_bc_matrix.h5 (cells after filtering, recommended to use), raw_feature_bc_matrix.h5 (without filtering), and two folders for MEX format output: filtered_feature_bc_matrix, raw_feature_bc_matrix. In addition, Cell Ranger also has a metrics_summary.csv file generated, which can be provided to scRNASequest. Please re-organize, and if necessary, rename the Cell Ranger output files into the following file structures before running scRNASequest. Below is the file hierarchy for h5 input files (metrics_summary.csv files are suggested to be included, but not required; If cell type classification annotation.csv files are available, it would be better to include them): Project/ ├── Data1.filtered_feature_bc_matrix.h5 ├── Data1.annotation.csv (optional) ├── Data1.metrics_summary.csv (optional) ├── Data2.filtered_feature_bc_matrix.h5 ├── Data2.annotation.csv (optional) ├── Data2.metrics_summary.csv (optional) ... The file hierarchy for MEX files: Project/ ├── Data1 ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ├── Data2 ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ... "],["input-configuration.html", "Chapter 6 Input configuration 6.1 Generate template files 6.2 Prepare the config.yml file 6.3 Prepare the sample meta file 6.4 File hierarchy", " Chapter 6 Input configuration First, make sure the .env has been created in the src folder under the pipeline directory: ls ~/scRNAsequest/src/.env 6.1 Generate template files Now we are ready to run the pipeline. Since the main pipeline script scAnalyzer requires a config.yml file, a sample metadata file sampleMeta.csv, and a DEGinfo.csv file for DE analysis (can be filled in later), we can first generate templates for these files. We run scAnalyzer by providing a path to our working directory. This can be any directory on you system: scAnalyzer /path/to/working/dir Then you will see the following files generate: config.yml #This is the pipeline configuration file DEGinfo.csv #This is for DE analysis, see the &#39;Differential expression (DE) analysis&#39; section for more details #This file can be left blank, which means skip DE analysis sampleMeta.csv #Sample metadata file, storing sample level information sc20230320.init.log #Log file In the log file, we can also see the following messages: ***** External data, please fill the config file and provide sample sheet with two mandatory columns: Two columns with names &#39;Sample_Name&#39; and &#39;h5path&#39; indicating sample name and UMI path Option columns for sample annotation Option column &#39;metapath&#39; can be provided for cell level annotation first column cell bar code ***** Please following the instructions below to set up these files. 6.2 Prepare the config.yml file To run the scRNAsequest pipeline, a config.yml file is required to be filled in. Please use the following template as an example to prepare this file: config.yml ## Project info and filtering parameters prj_name: E-MTAB-11115 #required, project name prj_title: &quot;Cell2location maps fine-grained cell types in spatial transcriptomics&quot; #required, and quotes might be needed ref_name: #optional. You can choose one from scAnalyzer call without an argument output: /home/ysun4/E-MTAB-11115/ #required, output path sample_name: Sample_Name sample_meta: ~/E-MTAB-11115/sampleMeta.csv #required, sample meta information, see section 5.1 gene_group: MT: startwith: [&quot;MT-&quot;,&quot;Mt-&quot;,&quot;mt-&quot;] cutoff: 20 # percentage cutoff to filter out the cells (larger than this cutoff) rm: False # this means the genes specified &quot;startwith&quot; will be REMOVED from the downstream analysis # The following is an example (Ribosomal genes) to add additional gene set/list to be quantified the percentage over total UMI per cell # additional gene set/list can be added as the format RP: startwith: [MRPL,MRPS,RPL,RPS] cutoff: 50 rm: False filter_step: True #if False, the above &#39;gene_group&#39; filtering will be skipped as well dbl_filter: True #if True, the dbl finding class will be used to remove the predicted doublets, if a numeric (0~1), cells with larger predicted doublet scores will be removed min.cells: 3 #filtering genes by minimal cell min.features: 50 #filtering cells by minimal genes highCount.cutoff: 10000 #any cells with higher total counts to be removed highGene.cutoff: 3000 #any cells with a higher number of detected genes to be removed group: #if provided, a 10X QC box plot will be ploted in QC plot rasterizeFig: True #should image in pdf be rasterized reRunQC: True #if satisfied with the above setting, please set this to False to save time runAnalysis: False #False means only run QC steps before data normalization and harmonization #If QC looks good, turn this to True to run the full pipeline newProcess: False methods: [SCT,Liger,SeuratRef,SeuratRPCA,sctHarmony] #SCT method (including log1p) is required expression normalization #The listed methods include all available analyses. If you want to ignore Liger, for example, you can delete it here expScaler: 10000 #integer value, 0: SCT (along with following option); 1-100: logNormal with scale.factor to be the specified quantile #&gt;100: logNormal with scale.factor to be the specified value PrepSCTFindMarkers: True # should the &quot;PrepSCTFindMarkers&quot; applied on SCT to be exported for visualization expression parallel: False #&quot;sge&quot; or &quot;slurm&quot; core: 2 overwrite: False #if you are rerunning the same project, set this to True to overwrite previous results major_cluster_rate: 0.7 #the proportion of cells of an integration cluster to be assigned to a seurat reference label ## DEG analysis for an annotation (such as disease vs health) within a cell type annotation DEG_desp: ~/E-MTAB-11115/DEGinfo.csv #required for DEG analysis, but you can leave this empty if not going to run DEG NAstring: [] #provide a list of strings which should be considered NA and associated cells to be removed # Please be causion of changing the following default filtering # More details can be found: section 2.4 in https://pubmed.ncbi.nlm.nih.gov/35743881/ # Applies the 1st round of biostats filtering pipeline. Note that this filter is applied to all cells of the experiment min.cells.per.gene: 3 # if `perc_filter` is FALSE, then keep only genes that have expression in at least min.cells.per.gene min.genes.per.cell: 250 # keep cells with expression in at least min.genes.per.cell genes. min.perc.cells.per.gene: 0.00 #if &#39;perc_filter&#39;`&#39; is TRUE, then keep only genes that have expression in at least min.per.cells.per.gene * 100 percent of cells perc_filter: TRUE # if TRUE, apply the cells.per.gene filter using percentages (expressed as a decimal) rather than an absolute threshold # Apply the 2nd round of biostats filtering. For &quot;group&quot; mode, the filtering is applied to `ref_group` and `alt_group` for the given cell type of interest. R6_min.cells.per.gene: 3 # minimum cells expressed per gene. This filter is applied if `R6_perc.cells.filter` is FALSE R6_min.perc.cells.per.gene: 0.1 # minimum % cells expressed per gene filtering (use decimal form of percentage). This threshold is applied if &#39;R6_perc.cells.filter&#39; is TRUE and &#39;R6_cells.per.gene.filter&#39; is TRUE R6_min.cells.per.gene.type: &quot;or&quot; # The type of cell per gene filtering. If it has the value &quot;and&quot; then it requires the gene be expressed in both reference and non-reference groups. If it has the value &quot;or&quot; then it requires the gene be expressed in either group R6_cells.per.gene.filter: TRUE # TRUE means apply cells per gene filtering R6_perc.cells.filter: TRUE # TRUE means apply cell.per.gene filtering by use of a percentage rather than absolute threshold. If the percentage results in a number less than R6_min.cells.per.gene, the code will automatically switch to min.cells.per.gene absolute thresholding R6_perc.filter: FALSE # If TRUE, then apply the 75th percentile gene filtering R6_perc.filter.type: &quot;and&quot; # The type of percentile gene filtering. If it has the value &quot;and&quot; then any gene that has 75th percentile of zero in both groups will be filtered out. If it has the value &quot;or&quot; then any gene that has a 75th percentile of zero in either group will be filtered out. R6_perc_threshold: 0.90 # Percentile threshold, 75th percentile is default. Express percentile as a decimal value. R6_min.ave.pseudo.bulk.cpm: 1 #cpm filtering threshold R6_pseudo.bulk.cpm.filter: FALSE # if TRUE, then apply a cpm filter on the pseudo-bulk counts R6_min.cells.per.subj: 3 # Minimum cells required per subject, must be a nonzero number ## publish to celldepot publish: False In the first run (see the below section 7.1 scAnalyzer section on how to run the pipeline), the user can set runAnalysis: False and use the above default parameters to perform cell filtering and QC. Then this pipeline will only run basic QC checking and output a Bookdown report with QC figures. This step is semi-automated because different datasets may need distinct filtering criteria. The design of this pipeline is to pause here to make sure the filtering step is adequate before running through the whole analysis. For HPC clusters, if you set parallel to be “sge” or “slurm” based on your cluster, the pipeline will automatically submit separate jobs and monitor the run. Finally, it will collect results and summarize them. Once the filtering step is validated by checking the QC report, the user can change the following settings and run the full analysis: runAnalysis: True overwrite: True 6.3 Prepare the sample meta file The sample meta file, usually named as sampleMeta.csv, is a csv file storing data information. The minimal columns for this file are Sample_Name (This name can be changed, but it must be consistent with the sample_name in the config.yml file) and h5path. If you have the cell type annotation information, you can provide is by adding a column called metapath, which is an optional column. For other information, you can add as many columns in this csv file and the column names can be defined by yourself. Another usage of the metapath column in sampleMeta.csv is to subset the cells. The pipeline will only use the cells included in the metapath file to run analysis. Thus, you can adjust this information by selecting only a subset of barcodes. 6.3.1 h5 input Here is an example with minimal information for the public dataset E-MTAB-11115 (10X h5 format): Sample_Name,h5path 5705STDY8058280,~/E-MTAB-11115/data/5705STDY8058280.filtered_feature_bc_matrix.h5 5705STDY8058281,~/E-MTAB-11115/data/5705STDY8058281.filtered_feature_bc_matrix.h5 5705STDY8058282,~/E-MTAB-11115/data/5705STDY8058282.filtered_feature_bc_matrix.h5 5705STDY8058283,~/E-MTAB-11115/data/5705STDY8058283.filtered_feature_bc_matrix.h5 5705STDY8058284,~/E-MTAB-11115/data/5705STDY8058284.filtered_feature_bc_matrix.h5 5705STDY8058285,~/E-MTAB-11115/data/5705STDY8058285.filtered_feature_bc_matrix.h5 Another example if you would like to use the cell type annotation defined by their analysis, which can be included in the metapath column. Moreover, the user has the freedom to provide further information such as sex and age: Sample_Name,h5path,metapath,sex,age 5705STDY8058280,~/E-MTAB-11115/data/5705STDY8058280_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058280_annotation.csv,Female,56d 5705STDY8058281,~/E-MTAB-11115/data/5705STDY8058281_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058281_annotation.csv,Female,56d 5705STDY8058282,~/E-MTAB-11115/data/5705STDY8058282_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058282_annotation.csv,Female,56d 5705STDY8058283,~/E-MTAB-11115/data/5705STDY8058283_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058283_annotation.csv,Male,56d 5705STDY8058284,~/E-MTAB-11115/data/5705STDY8058284_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058284_annotation.csv,Male,56d 5705STDY8058285,~/E-MTAB-11115/data/5705STDY8058285_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058285_annotation.csv,Male,56d #A brief look at the annotation file used in the metapath column: $ head -3 5705STDY8058280_annotation.csv Cell.ID,sample,annotation_1,annotation_1_print AAACCCAAGGAAGTAG-1,5705STDY8058280,Ext_L25,23_Ext_L25 AAACCCAAGGGCAGTT-1,5705STDY8058280,Ext_L56,24_Ext_L56 6.3.2 MEX input Since each data has three MEX files (barcodes.tsv.gz, features.tsv.gz and matrix.mtx.gz), here we provide the path to each MEX result directory. The minimal information in the sample meta file: Sample_Name,h5path FCtr,~/10XGenomicsData/GSM5617891_snRNA_FCtr FEcig,~/10XGenomicsData/GSM5617892_snRNA_FEcig MCtr,~/10XGenomicsData/GSM5617893_snRNA_MCtr MEcig,~/10XGenomicsData/GSM5617894_snRNA_MEcig Another example with additional information: Sample_Name,h5path,Treatment,Sex FCtr,~/10XGenomicsData/GSM5617891_snRNA_FCtr,Control,Female FEcig,~/10XGenomicsData/GSM5617892_snRNA_FEcig,EcTreated,Female MCtr,~/10XGenomicsData/GSM5617893_snRNA_MCtr,Control,Male MEcig,~/10XGenomicsData/GSM5617894_snRNA_MEcig,EcTreated,Male 6.4 File hierarchy Before running the pipeline, please check the file hierarchy. Here are examples for h5 and MEX inputs, and we suggest creating a separate folder (such as processing) to store the config.yml and sampleMeta.csv files. The output files will be generated in the directory specified in config.yml. For data downloaded in 10X h5 format: E-MTAB-11115/ ├── data ├── 5705STDY8058280.annotation.csv (optional) ├── 5705STDY8058280.metrics_summary.csv (optional) ├── 5705STDY8058280.raw_feature_bc_matrix.h5 ├── 5705STDY8058281.annotation.csv (optional) ├── 5705STDY8058281.metrics_summary.csv (optional) ├── 5705STDY8058281.raw_feature_bc_matrix.h5 ... ├── processing ├── config.yml └── sampleMeta.csv For data downloaded in 10X MEX format: GSE185538/ ├── GSM5617891_snRNA_FCtr ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ├── GSM5617892_snRNA_FEcig ├── barcodes.tsv.gz ├── features.tsv.gz └── matrix.mtx.gz ... ├── processing ├── config.yml └── sampleMeta.csv "],["running-the-pipeline.html", "Chapter 7 Running the pipeline 7.1 Initial scAnalyzer run 7.2 Review the bookdown report 7.3 Generate a slide deck 7.4 Doublet detection 7.5 Cell type label transfer 7.6 Adjust major_cluster_rate 7.7 Run the pipeline in parallel 7.8 Run the full analysis 7.9 Visualize the harmonized results", " Chapter 7 Running the pipeline If you would like to perform ambient RNA removal using CellBender, please follow the instruction here to run scRMambient first. The scRMambient pipeline will run CellBender based on unfiltered h5 input files and created new h5 files to run scAnalyzer. We have a detailed tutorial. After preparing the input data and configuration files (config.yml and sampleMeta.csv), we are ready to run the pipeline. Please be aware that scRNASequest is a semi-automated pipeline, and certain steps require the user to review the outputs and determine the parameters. Thus, the same step may need to be run for more than once, especially for finaling the QC parameters. 7.1 Initial scAnalyzer run The initial scAnalyzer run intends to test the default filtering parameters on the single-cell RNA-seq data. We suggest the following settings in the config.yml file to activate the filtering step, but pause the pipeline from additional analysis (such as data integration, harmonization, etc.): # Change the following settings in the config.yml file: filter_step: True runAnalysis: False To run scAnalyzer, simply pass the path to the config.yml file to the program: scAnalyzer Path/to/a/config/file #Example: scAnalyzer ~/E-MTAB-11115/processing/config.yml Output files: outputdir ├── BookdownReport/ #Full bookdown report folder. This is same as the BookdownReport.tar.gz below ├── config.yml ├── config.yml.20220617.log #log file ├── ProjName_BookdownReport.tar.gz #Bookdown report tar ball. #Please download this file and open the index.html file to view the report ├── ProjName_raw_prefilter.h5ad #h5ad after pre-filtering ├── prefilter.QC.pdf #QC plots before filtering. These plots are included in the Bookdown report ├── postfilter.QC.pdf #QC plots after filtering └── Rmarkdown/ #Source files for the Bookdown report 7.2 Review the bookdown report After the initial scAnalyzer run, a bookdown report, named ProjName_BookdownReport.tar.gz will be generated. Please open the report (index.html) to review cell numbers and figures before and after the filtering step, and adjust the following thresholds in the config.yml file if needed: # Cell filtering parameters in the config.yml file: gene_group: MT: startwith: [&quot;MT-&quot;,&quot;Mt-&quot;,&quot;mt-&quot;] cutoff: 20 #percentage cutoff to filter out the cells (larger than this cutoff) rm: False RP: #for ribosomal genes if you would like to filter them startwith: [] cutoff: 20 rm: False filter_step: True #if False, the above &#39;gene_group&#39; filtering will be skipped as well min.cells: 3 #filtering genes by minimum number of cells with non-zero count for a gene min.features: 50 #filtering cells by minimal genes detected highCount.cutoff: 10000 #any cells with higher total counts to be removed highGene.cutoff: 3000 #any cells with a higher number of detected genes to be removed The min.cells cutoff is to filter out genes that have low representation in cells, and the min.features cutoff is to filter out cells that have low number of genes (features) detected. The last two cutoffs, highCount.cutoff and highGene.cutoff can be used to filter cells if they have too many total counts or UMI detected, possibly due to multiplets. Please evaluate these cutoffs carefully, because the default values here may not be suitable for all datasets. The user may need to adjust the thresholds and rerun scAnalyzer to visualize the results. This step may be repeated until the threshold is adequate for the data. Please find an example of the bookdown report here: E-MTAB-11115 bookdown 7.3 Generate a slide deck This is an optional step if you have already reviewed the Bookdown report. This slide deck is another way to organize and present the same results. The QC report can be turned into a online slide deck format for better sharing and demonstration. To achieve this, please use the Slidedeck.Rmd file under the /src folder and follow the steps below: # create a new directory inside the project, and link the existed files and folder: cd ~/E-MTAB-11115/processing/ mkdir Slidedeck &amp;&amp; cd Slidedeck ln -s ../BookdownReport/images ln -s ../BookdownReport/bookdown.info.txt # Copy the Slidedeck.Rmd file from src directory to the working directory containing config.yml file. # We assume your pipeline was installed under ~/scRNAsequest/ cp ~/scRNAsequest/src/Slidedeck.Rmd ~/E-MTAB-11115/processing/Slidedeck # Source the environment src=&quot;~/scRNAsequest/src&quot; source $src/.env;eval $condaEnv # Run the Slidedeck script, and set the output file name using &#39;output_file&#39; parameter Rscript -e &#39;rmarkdown::render(&quot;Slidedeck.Rmd&quot;, output_file=&quot;Output.html&quot;)&#39; Please download the whole Slidedeck directory and open the Output.html file in a web browser. Please find an example of the bookdown report here: E-MTAB-11115 slidedeck 7.4 Doublet detection Based on the recent benchmarking paper and single-cell RNA-seq analysis guideline, we implement scDblFinder in our pipeline to perform doublet detection. By default, the pipeline runs scDblFinder on each sample and produces doublet scores (0-1, higher means high probability to be doublet) and classification results (singlet or doublet) using its own cutoff. If you speculate ambient RNA contamination in your data, we also suggest running scRMambient first. Users can control whether to remove these cells by setting dbl_filter in the config.yml file. False means not removing doublets, but the score (column name: scDblFinder.score) and classification (column name: scDblFinder.class) will be added to the final results for evaluation. If True, then all doublets will be removed. dbl_filter: False The scDblFinder automatically determines the doublet rates based on cell number, i.e., for N thousand cells, the doublet rate will be close to N %. However, you can adjust this manually by providing a numeric number between 0~1 in the config.yml file to enforce your own cutoff on the doublet score: dbl_filter: 0.95 7.5 Cell type label transfer Cell type label transfer is to label our new data using a reference single-cell RNA-seq data from the same tissue (i.e. brain, muscle, etc.). It automatically assigns cell types to each single cell. scRNASequest pipeline can do this if you provide a reference in the config.yml file. However, this is optional, so leaving ‘ref_name’ parameter as blank won’t affect running the pipeline. But we strongly suggest you perform label transfer to better understand the biology of the data. To check all available references, run scAnalyzer without any parameter and they will be printed out on the screen if you have added any references using scRef, see section Reference building. Alternatively, you can provide your own reference in Azimuth format to the pipeline. Example 1, if you have a named reference that has been added to the pipeline, for example, human_cortex is included already: ref_name: human_cortex Example 2, if you have an rds with cell type labels, you can also provide a path to the reference file and use it to label the current dataset. In the demo dataset, we have a reference rds file prepared and you can use it directly: ref_name: ~/scRNAsequest/rat_cortex_ref.rds The above rds file must be in Azimuth format, which can be prepared by running scRef. 7.6 Adjust major_cluster_rate If you have turned on cell type label transfer by providing a reference dataset, you may consider adjusting major_cluster_rate in the config.yml file. This major cluster rate means the proportion (by default 0.7) of cells of an integration cluster to be assigned to a Seurat reference label. In the final cell type labels, the predicted.celltype is the the labels predicted by Seurat label transfer. The following predicted labels: liger_cluster_predicted.celltype, normalized.louvain_predicted.celltype, raw.louvain_predicted.celltype, and sctHarmony_cluster.predicted.celltype are re-labelled cell types considering dimension reduction/integration clusters. The dimension reduction/integration algorithms generate numeric clusters, and our pipeline will look through each cluster and check if over 0.7 (by default, 70%) of the cells belong to one label. If yes, the whole cluster will be assigned to that cell type label. If not, it will leave that numeric cluster in the final result. We can consider those numeric labeling as a mixture or ‘Unclassified’ cell types. So, if you find cell type labels with just numbers and you don’t want to see them (The numbers indicating original cluster id whose cells belong to any label is lower than the threshold), you can turn this off by removing the default number 0.7 and leaving it empty like this in the config.yml file: major_cluster_rate: 7.7 Run the pipeline in parallel As mentioned in the previous section Input configuration, users can choose sge or slurm based on your scheduler option in the config.yml file to run your jobs parallelly. For large datasets, we highly recommend that users make full use of the CPU parallelization. Here is an example of using 8 cores on slurm HPC scheduler, in the config.yml file: parallel: slurm #False by default. Use &#39;slurm&#39; for Edge cluster, and use &#39;sge&#39; for Cambridge HPC core: 8 #Number of cores to use If you don’t have sge or slurm scheduler, simply use ‘parallel: False’ as default. 7.8 Run the full analysis We have finalized the filtering criteria and made necessary adjustment in the config.yml file to set up label transfer, major_cluster_rate, and parallelization. Now, we are ready to turn on the runAnalysis parameter in the config.yml and run the full pipeline: # Change the following setting in the config.yml file: runAnalysis: True overwrite: True #Overwrite the previous results if we run this again, for example, after adjusting some parameters. You can always go to our demo dataset to review related data and demo config.yml settings. Then run the following command again: scAnalyzer Path/to/a/config/file #Example: scAnalyzer ~/E-MTAB-11115/processing/config.yml This step will be time-consuming, and it took ~1 hour for the E-MTAB-11115 data (final cell number: 29,511) to finish. For a larger dataset with 110k cells we have tested, the full pipeline took ~7 hours. 7.9 Visualize the harmonized results After running the pipeline, you will see the following files in the working directory. Each harmonization method (Harmony, Seurat, Liger) will also generate corresponding files. outputdir # Input files ├── config.yml: The analysis config file specify the scAnalyzer parameters ├── sampleMeta.csv: List all sample information including expression matrix (and sample/cell level meta information) └── DEGinfo.csv: Define the sc DEG (between phenotypes within a cluster annotatino) # Main results under the output dir: ├── [prj_name].h5ad: The final h5ad file which is used for cellxgene VIP loading (will be copied into the celldepotDir folder set by sys.yml) ├── [prj_name].db: The final db file which is used for cellxgene VIP loading (will be copied into the celldepotDir folder set by sys.yml) ├── [prj_name].h5seurat: The h5seurat file of the final results └── [prj_name]_raw_added.h5ad: The h5ad file contains raw counts in X along with all annotation and embeding (will be copied into celldepot folder) # Rmarkdown: ├── Rmarkdown: The folder contains png files for R bookdown ├── [prj_name]_BookdownReport.tar.gz: R bookdown document tarball for downloading and sharing └── BookdownReport: The folder contains R bookdown reports # Log file: └── config.yml.[date].log: All stdout/stderr will be recorded in this dated log file └── [Software].error: Standard error files of multiple software, including: Harmony, Liger, SeuratRPCA, SeuratRef, SCT, sctHarmony, silhouette, etc. These files will be under the log/ directory if you did not run in the parallel mode These files will be under the j[numeric] folder if you ran the pipeline in the parallel mode # QC files under the QC/ folder: ├── sequencingQC.csv: Merged all sequence QC files from individual samples if available ├── sequencingQC.pdf: Plots of sequence QC if they are available ├── prefilter.QC.pdf: Initial data QC plots without filtering └── postfilter.QC.pdf: Data QC plots after filtering # evaluation folder for harmonization evaluation: ├── [prj_name]_kBET_umap_k0_100.pdf The kBET evaluation plot for all integration methods └── [prj_name]_Silhouette_boxplot_pc50.pdf The Silhouette evaluation plot for all integration methods # raw/ folder for h5ad files before and after QC, but have not run through the pipeline: ├── [prj_name]_raw_prefilter.h5ad: The internal temporary raw counts created/merged directly from sample before filtering └── [prj_name]_raw.h5ad: The internal temporary raw counts after the cell/gene filtering # SCT/ folder: ├── [prj_name].h5: The sparse matrix contains SCT expression values ├── [prj_name].h5.rds: The Seurat object contains counts (RNA assay) and SCT expression (SCT assay) along with original meta information from SampleMeta file ├── [prj_name].cID Cell barcodes ├── [prj_name].gID Gene ID ├── [prj_name].scalF Scale factor └── [prj_name].h5ad: The SCT expression, along with PCA, tSNE, UMAP reduction layout, will be merged into [prj_name].h5ad # SeuratRPCA folder for Seurat RPCA integration results: ├── [prj_name].csv.gz: The reuction embedding and clustering results from seurat RPCA integration └── [prj_name].h5ad: The seurat RPCA integration with reduction embedding and clustering, will be merged into [prj_name].h5ad # SeuratRef folder for Seurat reference mapping results: ├── [prj_name].csv: The reuction embedding and label transfer results from seurat RPCA integration └── [prj_name].h5ad: The seurat reference mapping results with reduction embedding, will be merged into [prj_name].h5ad # sctHarmony folder for Harmony based on SCT transformation: ├── [prj_name].csv: The PCA iinformation of each cell └── [prj_name].h5ad: The harmony integration with reduction embedding and clustering, will be merged into [prj_name].h5ad # Liger folder for Liger integration results: ├── [prj_name]_hvg.csv: High variable gene list ├── [prj_name].csv: The liger integration embedding and cluster └── [prj_name].h5ad&quot;: The liger integration with reduction embedding and clustering, will be merged into [prj_name].h5ad # [prj_name]_scDEG folder (if you ran the DEG step): ├── Comparisone names folders ├── .csv files for each cell type: The DEG analysis results ├── .rds files for each cell type: The rds data └── .pnd files for each cell type: The volcano plots # Parallel directory (if you ran the pipeline in parallel mode): └── j[numeric]: A colder contains parallel jobs submit script and log file kBET is a useful metric to evaluate and compare the harmonization results. Here is an example of the ProjName_kBET_umap_k0_100.pdf result: Please review the ProjName.h5ad file for the harmonization result. If you have Cellxgene VIP installed, the visualization will be easier. Here is an example of the ProjName.h5ad project visualized by Cellxgene VIP: "],["differential-expression-de-analysis.html", "Chapter 8 Differential expression (DE) analysis 8.1 Example 1 8.2 Example 2 8.3 Example 3", " Chapter 8 Differential expression (DE) analysis Another critical function of the scRNASequest pipeline is the Differential expression (DE) analysis. By running the steps in Section: Running the pipeline, we have performed quality control of the data, and generated an integrated dataset. Before running the DE analysis, the DEGinfo.csv comparison file needs to be prepared: The first column, comparisonName is designed to store the name of the comparison. These names will be used to create separate folders under the result directory. In the DEG comparison file above, “sample”, “cluster”, “group” and “covars” are the annotation headers, and “alt” and “ref” are the two entries from “group” column. The “covars” is optional and can be empty. The DEG is performing between “alt” and “ref” cells from “group” within each entry of “cluster” considering “sample” variations. The “group” variable should contain conditions to compare, such as Mutant v.s. Control. Thus, this pipeline is designed to loop through each cluster, and perform DEG analysis between “alt” v.s. “ref”. Covariate adjustment: Adjusting covariates is optional. By default, NEBULA considers the value of log of total UMI (library size) as the offset covariate in our pipeline, so you don’t need to adjust this again in “covars”. If needed, you can put a formula in the “covars” column using the meta information from the sampleMeta.csv file, such as Sex, Age, etc. You can also include QC metrics such as mitochondria percentage (pct_MT), etc. Please find a full list of QC metrics below. You can also open the Cellxgene VIP and check the right side. All numeric covariates are listed there. n_genes_by_counts, log1p_n_genes_by_counts, pct_counts_in_top_50_genes, pct_counts_in_top_100_genes, pct_counts_in_top_200_genes, pct_counts_in_top_500_genes, pct_MT, n_genes, predicted.CellType.score You may consider pct_MT as a covariate to adjust, but be careful to adjust other covariates here unless you have a good reason to do so. An example of the formula to be filled out in the “covars” column: Age+Sex+pct_MT. Missing values: It’s important to know that if any cells don’t have such DE condition information. For example, some samples don’t have information such as ‘treated’ or ‘control’ labeled, and instead, the values were ‘NA’, ‘NaN’, etc. In such case, we can easily include such information in the main config.yml file by defining the NA values to be ignored. The pipeline will remove all these cells from the DE analysis. #An example of the config.yml file: NAstring: [NA, NaN, NAN] #provide a list of strings which should be considered NA and associated cells to be removed DE software choices: Based on the previous benchmarking analysis, NEBULA outperforms other software in single-cell RNA-seq DE analysis. Thus, our pipeline uses NEBULA by default to run DE. However, we also offer the following methods as well, and you can directly use them in the DEGinfo.csv file, see Example 3 later. u_test: Mann–Whitney U test, also called Wilcoxon rank-sum test, is a nonparametric test. See Wiki. In our single-cell RNA-seq analysis, this is a pseudobulk method. t_test: Student’s t-test, statistical test based on Student’s t-distribution. See Wiki. In our single-cell RNA-seq analysis, this is a pseudobulk method. edgeR: Using the edgeR package to perform pseudobulk DE analysis. Refer to their paper for more details. limma: Using the limma-voom method to perform pseudobulk DE analysis. Refer to their paper for more details. DESeq2: Using the DESeq2 package to perform pseudobulk DE analysis. Refer to their paper for more details. ANCOVA: Using the ANCOVA to perform pseudobulk DE analysis. MAST: Using the MAST package to perform single-cell DE analysis. Refer to their paper for more details. NEBULA: Using the NEBULA software to perform single-cell DE analysis. Refer to their paper for more details. glmmTMB: Using the glmmTMB (nbinom2 family function) to perform single-cell DE analysis. limma_cell_level: This also uses limma but not a pseudobulk method. Here, this tutorial provides several examples to illustrate the DE analysis in scRNASequest: We use a UMAP with label transferred cell type annotation as an example dataset. Label transfer is strongly suggested if you would like to run DE analysis because the clusters are more meaningful than the original clusters assigned by the software: 8.1 Example 1 In the first example, we would like to run DE analysis between ‘Female’ and ‘Male’ for each cluster annotated by predicted.celltype1. In the first column, we input the header name library_id, which annotates the data sources. Then we add predicted.celltype1 in the cluster column, which allows the pipeline to loop through each cluster in predicted.celltype1. The group column contains the header name storing the comparison groups, and here we use the Sex annotation. Each time, the pipeline can only compare two conditions, such as ‘Female’ and ‘Male’. If the group column contains more groups, please list them in multiple lines in the DEGinfo.csv file. We can also add covars if needed, but this is optional. The default DE analysis is performed by NEBULA. As for the model, NEBULA provides two choices: HL and LN. For more details about them, please refer to the NEBULA manual. Here is the DEGinfo.csv we described above: comparisonName,sample,cluster,group,alt,ref,covars[+ separated],method[default NEBULA],model[default HL] Compare_Female_vs_Male,library_id,predicted.celltype1,Sex,Female,Male,,NEBULA,HL After preparing the DEGinfo.csv file, simply add it to the config.yml file: DEG_desp: ~/E-MTAB-11115/processing/DEGinfo.csv Then rerun the pipeline. The pipeline won’t run the previous steps (i.e. filtering, harmonization, etc.) again, so it will directly run the DE analysis based on the harmonized h5ad file. scAnalyzer Path/to/a/config/file #Example: scAnalyzer ~/E-MTAB-11115/processing/config.yml This step may take a few hours to run. The output files will be generated in the directory: outputdir ... previous results #Omitted, see section 6.4 ├── ProjName_scDEG #Folder containing DEG results ├── Compare_Female_vs_Male ├── Female.vs.Male_predicted.celltype1:astrocytes_NEBULA.csv #Each comparison has three associated files ├── Female.vs.Male_predicted.celltype1:astrocytes_NEBULA.png ├── Female.vs.Male_predicted.celltype1:astrocytes_NEBULA.QC.pdf ├── Female.vs.Male_predicted.celltype1:discarded_NEBULA.csv ├── Female.vs.Male_predicted.celltype1:discarded_NEBULA.png ├── Female.vs.Male_predicted.celltype1:discarded_NEBULA.QC.pdf ... └── env.rds An example of the DE csv table (Female.vs.Male_predicted.celltype1/astrocytes_NEBULA.csv, top 5 rows): In the table below, the most significant gene is Xist, a well-known X-chromosome gene highly expressed in female. Table 8.1: DEG analysis of Female.vs.Male in astrocytes res.tab.ID res.tab.log2FC res.tab.Pvalue res.tab.FDR res.tab.algorithm res.tab.convergence res.tab.metric res.ls.summary.logFC_.Intercept. res.ls.summary.logFC_.GrouPalt res.ls.summary.se_.Intercept. res.ls.summary.se_.GrouPalt res.ls.summary.p_.Intercept. res.ls.summary.p_.GrouPalt res.ls.summary.gene_id res.ls.summary.gene res.ls.overdispersion.Subject res.ls.overdispersion.Cell res.ls.convergence res.ls.algorithm Xist 9.676171 0 0 HL 1 6115.1780 -6.693213 0.1276737 0.0234622 0.0469395 0 0.0065289 1 Rgs20 0.0016728 0.4393152 1 NBGMM (HL) Pnpla7 -1.230034 0 0 HL 1 1653.1553 -9.321192 -0.1694550 0.0534180 0.1065177 0 0.1116405 2 Atp6v1h 0.0064320 0.3327316 1 NBGMM (HL) Etnppl -1.592058 0 0 HL 1 525.8328 -8.511808 0.0917939 0.0282832 0.0565059 0 0.1042691 3 Rb1cc1 0.0001000 0.1725113 1 NBGMM (HL) Zbtb16 -1.448309 0 0 HL 1 1260.9518 -9.896064 -0.0918014 0.0584728 0.1165549 0 0.4309170 4 4732440D04Rik 0.0014745 0.7288504 1 NBGMM (HL) Sorcs2 1.137956 0 0 HL 1 1398.0881 -8.573613 -0.2252848 0.0303869 0.0604625 0 0.0001945 5 Pcmtd1 0.0001000 0.3502587 -10 NBGMM (HL) An example of the DE png file (Female.vs.Male_predicted.celltype1/astrocytes_NEBULA.png): 8.2 Example 2 In the second example, we are going to show how to perform DE analysis between two cell types. To achieve this, we added one artificial column (called ‘SelectAll’) in the sampleMeta.csv file, and assigned the same values (‘Everything’) to all the data: Sample_Name,h5path,Sex,SelectAll 5705STDY8058280,/home/ysun4/testSinglecell/ExternalData/5705STDY8058280_filtered_feature_bc_matrix.h5,Female,Everything 5705STDY8058281,/home/ysun4/testSinglecell/ExternalData/5705STDY8058281_filtered_feature_bc_matrix.h5,Female,Everything 5705STDY8058282,/home/ysun4/testSinglecell/ExternalData/5705STDY8058282_filtered_feature_bc_matrix.h5,Female,Everything 5705STDY8058283,/home/ysun4/testSinglecell/ExternalData/5705STDY8058283_filtered_feature_bc_matrix.h5,Male,Everything 5705STDY8058284,/home/ysun4/testSinglecell/ExternalData/5705STDY8058284_filtered_feature_bc_matrix.h5,Male,Everything 5705STDY8058285,/home/ysun4/testSinglecell/ExternalData/5705STDY8058285_filtered_feature_bc_matrix.h5,Male,Everything Then we prepare the DEGinfo.csv file in this way. The ‘SelectAll’ was filled into the cluster column, and since it only has one value, it actually selects all cells when running the pipeline. Then it performs astrocytes to Oligos comparison. comparisonName,sample,cluster,group,alt,ref,covars[+ separated],method[default NEBULA],model[default HL] Comparison_Ast_vs_Oligo,library_id,SelectAll,predicted.celltype1,astrocytes,Oligos,,NEBULA,HL Then we need to run the scRNASequest pipeline from the beginning, which allows the ‘SelectAll’ column to be embedded into the harmonized h5ad output. As long as we have DEGinfo.csv included in the config.yml, it will run through the DE analysis and produce the following results: outputdir ... previous results #Omitted, see section 6.4 ├── ProjName_scDEG #Folder containing DEG results ├── Comparison_Ast_vs_Oligo ├── astrocytes.vs.Oligos_SelectAll:Everything_NEBULA.csv #Each comparison has three associated files ├── astrocytes.vs.Oligos_SelectAll:Everything_NEBULA.png ├── astrocytes.vs.Oligos_SelectAll:Everything_NEBULA.QC.pdf ├── env.rds ├── ProjName_scDEG.cmd.json ├── deg6602_SelectAll_predicted.celltype1_NEBULA_HL_Everything_astrocytes_Oligos.error #Standard error messages └── ProjName_scDEG.db An example of the DE csv table (astrocytes.vs.Oligos_SelectAll:Everything_NEBULA.csv, top 5 rows): Table 8.2: DEG analysis of astrocytes.vs.Oligos res.tab.ID res.tab.log2FC res.tab.Pvalue res.tab.FDR res.tab.algorithm res.tab.convergence res.tab.metric res.ls.summary.logFC_.Intercept. res.ls.summary.logFC_.GrouPalt res.ls.summary.se_.Intercept. res.ls.summary.se_.GrouPalt res.ls.summary.p_.Intercept. res.ls.summary.p_.GrouPalt res.ls.summary.gene_id res.ls.summary.gene res.ls.overdispersion.Subject res.ls.overdispersion.Cell res.ls.convergence res.ls.algorithm Xkr4 -3.327923 0 0 HL 1 4177.156 -8.168075 -2.3067403 0.0367924 0.0561022 0 0.0000000 1 Xkr4 0.0067297 0.6076303 1 NBGMM (HL) Rgs20 6.386205 0 0 HL 1 5561.771 -9.825703 -2.5066029 0.0890548 0.1353916 0 0.0000000 2 Gm1992 0.0398103 1.4947561 1 NBGMM (HL) St18 -5.129500 0 0 HL 1 14283.487 -10.322696 0.2176484 0.0310922 0.0690489 0 0.0016211 3 Mrpl15 0.0001000 0.4188721 1 NBGMM (HL) Adhfe1 4.842192 0 0 HL 1 12162.136 -10.169996 0.1119117 0.0292679 0.0669762 0 0.0947381 4 Tcea1 0.0001000 0.7212448 1 NBGMM (HL) Prex2 8.368190 0 0 HL 1 8249.837 -10.292221 4.4265797 0.0513462 0.0563860 0 0.0000000 5 Rgs20 0.0047768 0.4563594 1 NBGMM (HL) An example of the DE png file (astrocytes.vs.Oligos_SelectAll:Everything_NEBULA.png): 8.3 Example 3 In this example, we show how to perform DE analysis using multiple software. In the config file, each line is a comparison, and for the same comparison (treat v.s. control), we can set up multiple runs using different DE tools as below: comparisonName,sample,cluster,group,alt,ref,covars[+ separated],method[default NEBULA],model[default HL] Treated_vs_Control_nebula,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,NEBULA,HL Treated_vs_Control_t_test,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,t_test, Treated_vs_Control_u_test,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,u_test, Treated_vs_Control_edgeR,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,edgeR, Treated_vs_Control_limma,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,limma, Treated_vs_Control_DESeq2,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,DESeq2, Treated_vs_Control_MAST,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,MAST, Treated_vs_Control_limma_cell_level,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,limma_cell_level, Treated_vs_Control_glmmTMB,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,glmmTMB,poisson Treated_vs_Control_ancova,library_id,sctHarmony_cluster_predicted.celltype,Treatment,Treated,Vehicle,,ancova, Please note that NEBULA and glmmTMB require model information. For NEBULA, users can choose from HL and LN, and the pipeline uses ‘HL’ by default. The differences between them can be found in the NEBULA GitHub page: “NEBULA-LN is faster and performs particularly well when the number of cells per subject (CPS) is large. In addition, NEBULA-LN is much more accurate in estimating a very large subject-level overdispersion. In contrast, NEBULA-HL is slower but more accurate in estimating the cell-level overdispersion.” For glmmTMB, it is required to choose a model from the following: “nbinom2”, “nbinom1”, “poisson”, “nbinom2zi”, “nbinom1zi”. "],["reference-building.html", "Chapter 9 Reference building 9.1 Initialize scRef 9.2 Submit scRef 9.3 Demo scRef", " Chapter 9 Reference building Reference building is critical for label transfer. To add a reference dataset into the scRNASequest pipeline, the reference matrix needs to be SCT transformed. By running the following command, we can see the manual page of the reference generator, scRef: $ scRef ***** 2023-01-26 15:29:54 ***** ########### ## scRNAsequest: https://github.com/interactivereport/scRNAsequest.git ## Pipeline Path: /mnt/depts/dept04/compbio/edge_tools/scRNAsequest ## Pipeline Date: 2023-01-13 17:41:49 -0500 ## git HEAD: 3d463e0b127af499942b7adc2fc5af6ddfc6f11e ########### Loading resources scRef /path/to/a/output/folder === or === scRef /path/to/a/Ref/config/file The folder has to be existed. The Ref config file will be generated automatically when a path is provided ===== CAUTION ===== 1. This process will add a seurat reference data into the scRNAsequest pipeline PERMANENTLY! 2. Make sure the data provided for reference building is SCT transformed! Powered by the Research Data Sciences group [zhengyu.ouyang@biogen.com;kejie.li@biogen.com] ------------ 9.1 Initialize scRef This pipeline can be initialized using an empty directory. for example, we first create a directory called ‘Reference_data’, then initiate the pipeline pointing to this directory: scRef /path/to/the/directory #Example: scRef ~/Reference_data After the run, a config file, refConfig.yml, and a log file will be generated in the directory. The refConfig.yml is a template of the following scRef run, passing critical parameters to the pipeline. The refConfig.yml file will be same as this template, but the output directory will be yours. Here is an example after filling in the configuration file: output: ~/Reference_data # the following is normally located in the same folder of celldepot hosting h5ad files ref_h5ad_raw: /path/to/ProjectName_raw_added.h5ad # full path to the h5ad file contains raw UMI along with cell annotation and layout ref_batch: library_id # above two parameters are ignored, if a seurat object can be located in the project folder ref_rds: # full path to the processed seurat object including SCT assay, cell annotation and layout # All information below are required ref_name: Reference_data # Please provide a unique name prefer to include species and tissue (check existed by calling scAnalyzer without argument) ref_link: # The web link to the information of this reference. For scAnalyzer processed data, you could provide a Cellxgene VIP link here. ref_src: sn # sc/&quot;single cell&quot; or sn/&quot;single nuclei&quot; ref_platform: 10X # Single cell/neuclei technology e.g. 10X, SNARE-seq2, dropSeq, ... #list a reduction to be used (at least 50 dimensions full name from VIP or one from seurat &#39;reductions&#39; ) # details: https://github.com/satijalab/azimuth/wiki/Azimuth-Reference-Format # this reduction is NOT directly used, but used to find the neighbors which is then used for computing sPCA reduction which is used in the reference # For instance, if harmony was prefered layout then providing either &#39;harmony&#39; (50 dimention) or &#39;harmony-PCA&#39; ref_reduction: pca ref_label: [predicted.celltype1] # List the annotations (case sensitive) to be used for transferring. Please check this in the data. For our case, the header is called &#39;predicted.celltype1&#39; # The cell type label/header name you would like to transfer publish: False # Should this reference be published (added permanently) into scAnalyzer overwrite: False # Overwrite the existing scAnalyzer reference For the input data, scRef can take either an h5ad file containing raw UMI and annotatino information, or an R data file in rds format. If you have finished running a dataset using scAnalyzer, then you can directly use the ProjectName_raw_added.h5ad (not ProjectName.h5ad file) as input, and attach its path to ref_h5ad_raw. Alternatively, you can provide an RDS file using ref_rds. Either providing ref_h5ad_raw or ref_rds would be sufficient to the pipeline. The ref_label is critical for label transfer if you would like to use this data as a reference in the future. It tells the program to use the cell type information in these (can be one more more) headers to perform label transfer. For a h5ad data, the easiest way is to open it using Cellxgene VIP, and identify the header that contains cell type labels, e.g. predicted.celltype1 in our case. For an RDS data, you could read it in R using the readRDS function and identify the column names containing cell type annotation. For ref_rds input RDS file, please make sure it has been SCTransformed, and includes UMAP embeddings based on SCT values. Here are some codes to prepare it: library(Seurat) Data &lt;- readRDS(&quot;Annotated.rds&quot;) #The meta.data table already has cell types annotated Data &lt;- SCTransform(Data, return.only.var.genes = F) #Turn return.only.var.genes off Data &lt;- RunPCA(Data, verbose = FALSE) Data &lt;- RunUMAP(Data, dims = 1:30, verbose = FALSE) Data &lt;- FindNeighbors(Data, dims = 1:30, verbose = FALSE) Data &lt;- FindClusters(Data, verbose = FALSE) saveRDS(Data, file = &quot;Annotated.ForRuningscRef.rds&quot;) 9.2 Submit scRef After filling in the information in the refConfig.yml file, we are ready to submit the full pipeline and build the reference data for label transfer: scRef /path/to/a/Ref/config/file #Example: scRef ~/Reference_data/refConfig.yml Output files: Reference_data ├── init_20220630.log ├── refConfig.yml ├── refConfig.yml.20220630.log # Output log information ├── Reference_data_for_scAnalyzer.rds # The data to use for label transfer and downstream analysis ├── ref_notFor_scAnalyzer.rds # Output rds file NOT for lebel transfer ... Please also check the information in the refConfig.yml.20220630.log file, and pay attention to the last few lines: ... #log of the running process omitted The private reference could be used by provide the following full path to &#39;ref_name&#39; in scAnalyzer config file: ~/Reference_data/Reference_data_for_scAnalyzer.rds ... This indicates that the reference has been successfully generated, and it can be passed to scAnalyzer through the config.yml file. If you turned on “publish: True” in the refConfig.yml, this reference will be added to scAnalyzer, and you can use its name to refer it when running scAnalyzer. 9.3 Demo scRef In this demo, we use a previously processed RDS file using cell type annotation from a public project: GSE172462. The RDS file is: GSE172462.SCT.For_scRef.rds. We first run scRef by providing our working directory to generate necessary template files: scRef ~/demo_scRef Then we fill in the refConfig.yml file: # please check wiki page for the details output: ~/demo_scRef # the following is normally located in the same folder of celldepot hosting h5ad files ref_h5ad_raw: # full path to the h5ad file contains raw UMI along with cell annotation and layout ref_batch: library_id # above two parameters are ignored, if a seurat object can be located in the project folder ref_rds: ~/demo_scRef/GSE172462.SCT.For_scRef.rds #full path to the processed seurat object including SCT assay, cell annotation and layout # All information below are required ref_name: demo # please provide a unique name prefer to include species and tissue (check existed by calling scAnalyzer without argument) ref_link: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE172462 # The web link to the information of this reference ref_src: single nuclei # sc/&quot;single cell&quot; or sn/&quot;single nuclei&quot; ref_platform: 10X # which single cell/neuclei technology e.g. 10X, SNARE-seq2, dropSeq, ... #list a reduction to be used (at least 50 dimensions full name from VIP or one from seurat &#39;reductions&#39; ) # details: https://github.com/satijalab/azimuth/wiki/Azimuth-Reference-Format # this reduction is NOT directly used, but used to find the neighbors which is then used for computing sPCA reduction which is used in the reference # For instance, if harmony was prefered layout then providing either &#39;harmony&#39; (50 dimention) or &#39;harmony-PCA&#39; ref_reduction: pca ref_label: [celltype, neuron_subtype, manual_anno] # list the annotations (case sensitive) to be used for transferring publish: False # should this reference be published into scAnalyzer overwrite: False # overwrite the existing scAnalyzer reference In this demo, we turned off publish and overwrite to make it just to test scRef. This is a reduced data (with only 1000 files) to test the demo, so it may not be ideal to use it as a real reference in the pipeline. Finally, we can run the scRef: scRef ~/demo_scRef/refConfig.yml This pipeline will finish in ~1 minute and the output file will be: demo_for_scAnalyzer.rds "],["celldepot-publishing.html", "Chapter 10 CellDepot publishing 10.1 Initialize sc2celldepot 10.2 Run sc2celldepot 10.3 Demo sc2celldepot", " Chapter 10 CellDepot publishing CellDepot is a comprehensive data management platform for single-cell RNA-seq datasets. Publishing to CellDepot allows easy navigation and visualization of the data, and facilitates big data deposition. If you have run through the scRNASequest pipeline using scAnalyzer, you will be able to use the h5ad file directly and add it to CellDepot, following the ‘4.6 Import projects’ and ‘4.7 Create project’ in the full instruction here. In this case, you won’t need to run sc2celldepot. However, this may be cumbersome because you have to run the full scAnalyzer pipeline to get the h5ad files. Sometimes, you have a public data (such as an RDS file, or raw MEX/h5 UMI count files with UMAP coordinates) with cell annotation information, and you only need to use them for visualization, rather than running though the whole analysis. Thus, the scRNASequest pipeline offers a function to publish a dataset to CellDepot using sc2celldepot. This workflow will use the existing cell type information (cell type, cluter id, etc.) and create an h5ad file. The h5ad file can be further used for uploading to the CellDepot platform. In sum, there are two cases to use this pipeline: 1) If your input is an RDS file, you can also view this pipeline as a converter from RDS to h5ad. 2) If you have raw UMI counts, together with annotated cell barcode information (e.g. cell type for each barcode), and some UMAP embedding coordinates (the embedding information is optional), you can use this pipeline to assemble them together and create an h5ad output. By running the following command, we can see the manual page of the script: $ sc2celldepot ***** 2023-01-26 15:25:32 ***** ########### ## ExpressionAnalysis: https://github.com/interactivereport/scRNAsequest.git ## Pipeline Path: /mnt/depts/dept04/compbio/edge_tools/scRNAsequest ## Pipeline Date: 2023-01-13 17:41:49 -0500 ## git HEAD: 3d463e0b127af499942b7adc2fc5af6ddfc6f11e ########### Loading resources sc2celldepot /path/to/a/output/folder === or === sc2celldepot /path/to/a/config/file Please create the folder before running sc2celldepot. The data config file will be generated automatically when a path is provided Powered by the Research Data Sciences Group [zhengyu.ouyang@biogen.com;yuhenry.sun@biogen.com] ------------ 10.1 Initialize sc2celldepot Running sc2celldepot by providing a working directory will initiate the project and generate a template of config file. The config file template can be found: template. First, we create a new directory under the project. Then we run the sc2celldepot command: mkdir ~/E-MTAB-11115/CellDepot_publish sc2celldepot ~/E-MTAB-11115/CellDepot_publish E-MTAB-11115/ ├── E-MTAB-11115.rds └── CellDepot_publish └── sc2celldepot.yml Here is an example after filling in the configuration sc2celldepot.yml file. For a simple example, we just provide a prefix and an RDS file path to this yml file. The pipeline will read the metadata and convert it to an h5ad file. ## The config file to process public sc/sn RNAseq and generate h5ad for celldepot output: ~/E-MTAB-11115/CellDepot_publish prefix: E-MTAB-11115 # the prefix of the file name of the h5ad # seurat RDS is avaiable, otherwise please move to next section seuratObj: ~/E-MTAB-11115/E-MTAB-11115.rds # the full path to the seurat RDS file with SCT &amp; RNA assay along with meta.data and reduction seuratUMI: RNA # the name of the assay stores raw UMI seuratSCT: SCT # the name of the assay stores SCT seuratMeta: [] # the list of cell annotations to be stored in h5ad, empty list means all meta.data entry from seurat rds # Expression when the seurat RDS is not available (row gene/column cell) # if the annotation files are seperated the same as expression files, they should be the same order, other wise cell ID will be used to match expression: [] # full path the gene expression file/folder (h5/csv/txt/mtx), if multiple files, please provide the list separated by &#39;,&#39; dataUMI: True # if the above expression is UMI, if the value in expression file should be used directly, please set &quot;False&quot; # cell annotation (cell intersection will be used, first column is the cell ID) annotation: [] # full path to the cell annotation file, first column is the cell ID which should match cell ID in expression annotationUse: [] # the column names in the annotation file to be extracted for h5ad, empty list means all columns sample_column: # one column header from annotation file, if the one expression file needs to be splited into each sample # cell layout: tSNE, UMAP, PCA, if separated the same as expression files, should be the same order reduction: # optional (if missing UMAP will be created), other keys can be removed or added new ones, keys will be used in h5ad files: [] # full path to the cell layout file (contains all layouts of a set of cells), first column is the cell ID which should match cell ID in expression umap: [] # column headers from layout file to be used, please use quote for each column header tsne: [] # column headers from layout file to be used, please use quote for each column header pca: [] # column headers from layout file to be used, please use quote for each column header (can be more than 2 dimentions though only first two will be shown in VIP) Alternatively, if you don’t have an RDS file, users can provide raw UMI files together with cell type annotation files and reduction embeddings (optional, by default it will generate UMAP) in this way: Besides the required output and prefix parameters, in this example, the expression points to several h5 files or MEX folders, which is required. The annotation points to cell type annotation (and other cell level information) csv files, which are also required. ## The config file to process public sc/sn RNAseq and generate h5ad for celldepot output: ~/E-MTAB-11115/CellDepot_publish prefix: E-MTAB-11115 # the prefix of the file name of the h5ad # seurat RDS is avaiable, otherwise please move to next section seuratObj: # the full path to the seurat RDS file with SCT &amp; RNA assay along with meta.data and reduction seuratUMI: RNA # the name of the assay stores raw UMI seuratSCT: SCT # the name of the assay stores SCT seuratMeta: [] # the list of cell annotations to be stored in h5ad, empty list means all meta.data entry from seurat rds # Expression when the seurat RDS is not available (row gene/column cell) # if the annotation files are seperated the same as expression files, they should be the same order, other wise cell ID will be used to match expression: [~/E-MTAB-11115/data/5705STDY8058280_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058281_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058282_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058283_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058284_filtered_feature_bc_matrix.h5,~/E-MTAB-11115/data/5705STDY8058285_filtered_feature_bc_matrix.h5] # full path the gene expression file/folder (h5/csv/txt/mtx), if multiple files, please provide the list separated by &#39;,&#39; dataUMI: True # if the above expression is UMI, if the value in expression file should be used directly, please set &quot;False&quot; # cell annotation (cell intersection will be used, first column is the cell ID) annotation: [~/E-MTAB-11115/data/5705STDY8058280_annotation.csv,~/E-MTAB-11115/data/5705STDY8058281_annotation.csv,~/E-MTAB-11115/data/5705STDY8058282_annotation.csv,~/E-MTAB-11115/data/5705STDY8058283_annotation.csv,~/E-MTAB-11115/data/5705STDY8058284_annotation.csv,~/E-MTAB-11115/data/5705STDY8058285_annotation.csv] # full path to the cell annotation file, first column is the cell ID which should match cell ID in expression annotationUse: [] # the column names in the annotation file to be extracted for h5ad, empty list means all columns sample_column: # one column header from annotation file, if the one expression file needs to be splited into each sample # cell layout: tSNE, UMAP, PCA, if separated the same as expression files, should be the same order reduction: #optional (if missing UMAP will be created), other keys can be removed or added new ones, keys will be used in h5ad files: [] # full path to the cell layout file (contains all layouts of a set of cells), first column is the cell ID which should match cell ID in expression umap: [] # column headers from layout file to be used, please use quote for each column header tsne: [] # column headers from layout file to be used, please use quote for each column header pca: [] # column headers from layout file to be used, please use quote for each column header (can be more than 2 dimentions though only first two will be shown in VIP)``` 10.2 Run sc2celldepot After preparing the sc2celldepot.yml file, we are ready to run the pipeline by the following command: sc2celldepot ~/E-MTAB-11115/CellDepot_publish/sc2celldepot.yml This workflow will generate the output files in the working directory, CellDepot_publish: The output prefix is determined by the prefix parameter in the sc2celldepot.yml file. E-MTAB-11115/ ├── E-MTAB-11115.rds └── CellDepot_publish ├── E-MTAB-11115.h5ad ├── E-MTAB-11115.raw_added.h5ad └── sc2celldepot.yml Finally, copy the E-MTAB-11115.h5ad to the CellDepot folder defined by sys.yml (celldepotDir) and follow the instructions for publishing it. 10.3 Demo sc2celldepot To demo sc2celldepot, we use the following RDS file (GSE172462.SCT.For_scRef.rds), which we had used it to demo scRef. This RDS file contains cell type labeling and embedding information. Please download it to the working directory, for example, ~/demo_celldepot. Then we run the sc2celldepot program by providing a working directory, in our case: sc2celldepot ~/demo_celldepot File hierarchy after running the above command: ~/demo_celldepot ├── GSE172462.SCT.For_scRef.rds └── sc2celldepot.yml We set up the sc2celldepot.yml in the following way, by just adding information to prefix and seuratObj: ## The config file to process public sc/sn RNAseq and generate h5ad for celldepot output: ~/demo_celldepot prefix: demo_sc2celldepot # the prefix of the file name of the h5ad # seurat RDS is avaiable, otherwise please move to next section seuratObj: ~/demo_celldepot/GSE172462.SCT.For_scRef.rds # the full path to the seurat RDS file with SCT &amp; RNA assay along with meta.data and reduction seuratUMI: RNA # the name of the assay stores raw UMI seuratSCT: SCT # the name of the assay stores SCT seuratMeta: [] # the list of cell annotations to be stored in h5ad, empty list means all meta.data entry from seurat rds # Expression when the seurat RDS is not available (row gene/column cell) # if the annotation files are seperated the same as expression files, they should be the same order, other wise cell ID will be used to match expression: [] # full path the gene expression file/folder (h5/csv/txt/mtx), if multiple files, please provide the list separated by &#39;,&#39; dataUMI: True #if the above expression is UMI, if the value in expression file should be used directly, please set &quot;False&quot; # cell annotation (cell intersection will be used, first column is the cell ID) annotation: [] # full path to the cell annotation file, first column is the cell ID which should match cell ID in expression annotationUse: [] # the column names in the annotation file to be extracted for h5ad, empty list means all columns sample_column: # one column header from annotation file, if the one expression file needs to be splited into each sample # cell layout: tSNE, UMAP, PCA, if separated the same as expression files, should be the same order reduction: #optional (if missing UMAP will be created), other keys can be removed or added new ones, keys will be used in h5ad files: [] # full path to the cell layout file (contains all layouts of a set of cells), first column is the cell ID which should match cell ID in expression umap: [] # column headers from layout file to be used, please use quote for each column header tsne: [] # column headers from layout file to be used, please use quote for each column header pca: [] # column headers from layout file to be used, please use quote for each column header (can be more than 2 dimentions though only first two will be shown in VIP) Then run the pipeline: sc2celldepot ~/demo_celldepot/sc2celldepot.yml The results will be new h5ad files as below: ~/demo_celldepot ├── demo_sc2celldepot_rds.h5ad ├── demo_sc2celldepot_rds.raw_added.h5ad ├── GSE172462.SCT.For_scRef.rds ├── sc2celldepot.20230321.log └── sc2celldepot.yml We provide another demo using two h5 data files from our previous demo dataset. Besides that, we also need two cell level annotation files, and I have prepared them: RatMaleCigarette.annotation.csv, RatFemaleCigarette.annotation.csv. Take a quick look of the csv files (Usually, the cell barcodes in the list is only a subset of all barcodes in the h5, due to filtering in previous analysis): $ head -3 RatMaleCigarette.annotation.csv ,library_id,predicted.celltype AAACCCACAACTGAAA-1,RatFemaleCigarette,OPC AAACCCACACTTTATC-1,RatFemaleCigarette,Neuron Please organize these four files (2 h5 files, 2 csv files) in the working dir (in this demo: ~/demo_celldepot_2), then run the script: sc2celldepot ~/demo_celldepot_2 The above run generated sc2celldepot.yml, and the current file hierarchy is: ~/demo_celldepot_2 ├── RatFemaleCigarette.annotation.csv ├── RatFemaleCigarette.filtered_feature_bc_matrix.h5 ├── RatMaleCigarette.annotation.csv ├── RatMaleCigarette.filtered_feature_bc_matrix.h5 └── sc2celldepot.yml Then we set up the sc2celldepot.yml file in this way: ## The config file to process public sc/sn RNAseq and generate h5ad for celldepot output: ~/demo_celldepot_2 prefix: demo_sc2celldepot_2 # the prefix of the file name of the h5ad # seurat RDS is avaiable, otherwise please move to next section seuratObj: # the full path to the seurat RDS file with SCT &amp; RNA assay along with meta.data and reduction seuratUMI: RNA # the name of the assay stores raw UMI seuratSCT: SCT # the name of the assay stores SCT seuratMeta: [] # the list of cell annotations to be stored in h5ad, empty list means all meta.data entry from seurat rds # Expression when the seurat RDS is not available (row gene/column cell) # if the annotation files are seperated the same as expression files, they should be the same order, other wise cell ID will be used to match expression: [~/demo_celldepot_2/RatMaleCigarette.filtered_feature_bc_matrix.h5,~/demo_celldepot_2/RatFemaleCigarette.filtered_feature_bc_matrix.h5] # full path the gene expression file/folder (h5/csv/txt/mtx), if multiple files, please provide the list separated by &#39;,&#39; dataUMI: True #if the above expression is UMI, if the value in expression file should be used directly, please set &quot;False&quot; # cell annotation (cell intersection will be used, first column is the cell ID) annotation: [~/demo_celldepot_2/RatMaleCigarette.annotation.csv,~/demo_celldepot_2/RatFemaleCigarette.annotation.csv] # full path to the cell annotation file, first column is the cell ID which should match cell ID in expression annotationUse: [] # the column names in the annotation file to be extracted for h5ad, empty list means all columns sample_column: # one column header from annotation file, if the one expression file needs to be splited into each sample # cell layout: tSNE, UMAP, PCA, if separated the same as expression files, should be the same order reduction: #optional (if missing UMAP will be created), other keys can be removed or added new ones, keys will be used in h5ad files: [] # full path to the cell layout file (contains all layouts of a set of cells), first column is the cell ID which should match cell ID in expression umap: [] # column headers from layout file to be used, please use quote for each column header tsne: [] # column headers from layout file to be used, please use quote for each column header pca: [] # column headers from layout file to be used, please use quote for each column header (can be more than 2 dimentions though only first two will be shown in VIP) This will let the pipeline to process the h5 files by running normalization, and match labeled cell types to the UMAP. Files after running the pipeline: ~/demo_celldepot_2 ├── demo_sc2celldepot.h5ad ├── demo_sc2celldepot.raw_added.h5ad ├── demo_sc2celldepot.rds ├── RatFemaleCigarette.annotation.csv ├── RatFemaleCigarette.filtered_feature_bc_matrix.h5 ├── RatMaleCigarette.annotation.csv ├── RatMaleCigarette.filtered_feature_bc_matrix.h5 └── sc2celldepot.yml "],["additional-tools.html", "Chapter 11 Additional tools 11.1 scRMambient 11.2 scDEG 11.3 scTool", " Chapter 11 Additional tools 11.1 scRMambient scRMambient removes ambient RNA using the raw h5 file (raw_feature_bc_matrix.h5) as input, run CellBender, and output new h5 files for downstream analysis. 11.1.1 Set up the inputs Besides the raw h5 file (raw_feature_bc_matrix.h5), the only required file for scRMambient is a sampleMeta_raw.csv file. There are several columns that are required: h5path, expected_cells, droplets_included, low_count_threshold,learning_rate. You can also add more sample metadata information, and they will be carried to a new sampleMeta.csv file generated after running scRMambient. Users can use that new sampleMeta.csv (it also contains some information related to CellBender run) to perform downstream scAnalyzer run. expected_cells: This is the number of cells output by the Cell Ranger pipeline. We directly use the number here. droplets_included: This is a critical parameter for CellBender. Please follow the instruction here to set it. We found that in many cases 15000 is a good number, but it also depends on your data. low_count_threshold: We set to 15 by default. learning_rate: We set to 0.0001 by default. File hierarchy of the inputs: ~/test_ambient_rna_removal ├── Data1.raw_feature_bc_matrix.h5 ├── Data2.raw_feature_bc_matrix.h5 └── sampleMeta_raw.csv An example of the sampleMeta_raw.csv file: Sample_Name,h5path,expected_cells,droplets_included,low_count_threshold,learning_rate Data1,~/test_ambient_rna_removal/Data1.raw_feature_bc_matrix.h5,8119,15000,15,0.0001 Data2,~/test_ambient_rna_removal/Data2.raw_feature_bc_matrix.h5,7348,15000,15,0.0001 11.1.2 Run scRMambient Then we run the pipeline: scRMambient ~/test_ambient_rna_removal/sampleMeta_raw.csv The output will be a new directory called cellbender, with new h5 files generated under the h5/ directory. The file hierarchy is: ~/test_ambient_rna_removal ├── cellbender ├── all_cellbender.pdf # Plots generated by CellBender ├── all.log ├── cellbender_QC.pdf # QC plots ├── cellbender_rmRate.csv # Metrics related to the final cell number, and cell removal rates ├── h5/ # Directory for all output h5 files with ambient RNA removed ├── Data1.cellbender_cell_barcodes.csv ├── Data1.cellbender_filtered.h5 ├── Data1.cellbender_filtered_qc.csv ├── Data1.cellbender.h5 ├── Data1.cellbender.log ├── Data1.cellbender.pdf ├── ... ├── sc20230317_0 # File directory prepared for running scAnalyzer ├── config.yml ├── DEGinfo.csv └── sampleMeta.csv # In this file, &#39;h5path&#39; points to all new h5 files ├── Data1.raw_feature_bc_matrix.h5 ├── Data2.raw_feature_bc_matrix.h5 └── sampleMeta_raw.csv 11.2 scDEG scDEG is a standalone pipeline to run the differential expression (DE) analysis independently if you alreadly have integrated scRNA-seq data in h5ad format. scDEG uses the same methods as in the scRNASequest pipeline to run DE analysis. It just provides a flexible way to apply the same analysis outside the pipeline. 11.2.1 Initialize scDEG scDEG requires three files: UMI: Gene counts matrix, can be in rds or h5ad format. Meta: cell type annotation and related meta information for DE analysis, in h5ad format. If you have this information in your h5ad matrix already, you can provide the same file twice (as UMI and meta file). config.yml: file storing the above UMI file path and meta data path, as well as the output file path. By running the scDEG without providing any parameters, we can see the manual page of the script: $ scDEG scDEG /path/to/a/folder === or === scDEG /path/to/a/config/file An empty config file will be generated automatically when a folder is provided Powered by the Research Data Sciences Group [zhengyu.ouyang@biogen.com;yuhenry.sun@biogen.com] ------------ Then providing a directory to scDEG, and it will generate a template config file: $ scDEG /path/to/a/folder #Example: scDEG ~/DEG_results Template configuration file: UMI: /path/to/Prefix.h5ad #required, can be a matrix rds or a h5ad file meta: /path/to/Prefix.h5ad #required, can be a cell annotation data.frame rds or a h5ad file output: /path/to/output/directory DBname: cellxgeneVIP parallel: slurm # False or &quot;sge&quot; or &quot;slurm&quot; ## DEG analysis for an annotation (such as disease vs health) within a cell type annotation DEG_desp: /path/to/DEGinfo.csv #required for DEG analysis # Please be causion of changing the following default filtering # More details can be found: section 2.4 in https://pubmed.ncbi.nlm.nih.gov/35743881/ # Applies the 1st round of biostats filtering pipeline. Note that this filter is applied to all cells of the experiment min.cells.per.gene: 3 # if `perc_filter` is FALSE, then keep only genes that have expression in at least min.cells.per.gene min.genes.per.cell: 250 # keep cells with expression in at least min.genes.per.cell genes. min.perc.cells.per.gene: 0.00 #if &#39;perc_filter&#39;`&#39; is TRUE, then keep only genes that have expression in at least min.per.cells.per.gene * 100 percent of cells perc_filter: TRUE #if TRUE, apply the cells.per.gene filter using percentages (expressed as a decimal) rather than an absolute threshold # Apply the 2nd round of biostats filtering. For &quot;group&quot; mode, the filtering is applied to `ref_group` and `alt_group` for the given cell type of interest. R6_min.cells.per.gene: 3 #minimum cells expressed per gene. This filter is applied if `R6_perc.cells.filter` is FALSE R6_min.perc.cells.per.gene: 0.1 # minimum % cells expressed per gene filtering (use decimal form of percentage). This threshold is applied if &#39;R6_perc.cells.filter&#39; is TRUE and &#39;R6_cells.per.gene.filter&#39; is TRUE R6_min.cells.per.gene.type: &quot;or&quot; #The type of cell per gene filtering. If it has the value &quot;and&quot; then it requires the gene be expressed in both reference and non-reference grou ps. If it has the value &quot;or&quot; then it requires the gene be expressed in either group R6_cells.per.gene.filter: TRUE #TRUE means apply cells per gene filtering R6_perc.cells.filter: TRUE #TRUE means apply cell.per.gene filtering by use of a percentage rather than absolute threshold. If the percentage results in a number less than R6_m in.cells.per.gene, the code will automatically switch to min.cells.per.gene absolute thresholding R6_perc.filter: FALSE #If TRUE, then apply the 75th percentile gene filtering R6_perc.filter.type: &quot;and&quot; #The type of percentile gene filtering. If it has the value &quot;and&quot; then any gene that has 75th percentile of zero in both groups will be filtered out. If it has the value &quot;or&quot; then any gene that has a 75th percentile of zero in either group will be filtered out. R6_perc_threshold: 0.90 #Percentile threshold, 75th percentile is default. Express percentile as a decimal value. R6_min.ave.pseudo.bulk.cpm: 1 #cpm filtering threshold R6_pseudo.bulk.cpm.filter: FALSE #if TRUE, then apply a cpm filter on the pseudo-bulk counts R6_min.cells.per.subj: 3 #Minimum cells required per subject, must be a nonzero number The UMI file can be a matrix rds or a h5ad file. The meta file can be a data.frame rds or a h5ad file, containing critical information that can be used for DE analysis. ## The config file for scDEG UMI: ~/DEG_results/TST12055_raw_added.h5ad #required, can be a matrix rds or a h5ad file meta: ~/DEG_results/TST12055_raw_added.h5ad #required, can be a cell annotation data.frame rds or a h5ad file output: ~/DEG_results/ DBname: cellxgeneVIP ## DEG analysis for an annotation (such as disease vs. health) within a cell type annotation DEG_desp: ~/DEG_results/DEGinfo.csv #required for DEG analysis ## Please be cautious of changing the following default filtering. min.cells.per.gene: 3 min.genes.per.cell: 250 min.perc.cells.per.gene: 0.00 perc_filter: TRUE ## ... 11.2.2 Run DE analysis Please refer the previous section Differential expression (DE) analysis to prepare the DE comparison file. After preparing the config.yml and DEGinfo.csv files, run the pipeline: $ scDEG /path/to/config.yml #Example: scDEG ~/DEG_results/config.yml 11.3 scTool We also provide scTool, a user-friendly toolkit for modifying the h5ad file. With scTool, the user can: Remove existing annotations in the data, such as the cell type annotation. Add cell type annotation by providing a two-column csv file, specifying the cell type category of each single cell. Export a list of genes along with all annotation. By running the scTool without providing any parameters, we can see the manual page of the script: $ scTool usage: scTool.py [-h] {rm,add,export} h5ad [changes] Additional sc tools. WARNING: The input h5ad files will be over-written! positional arguments: {rm,add,export} Modify the h5ad by either &quot;rm&quot;, &quot;add&quot; or &quot;export&quot; cell level annotations. h5ad Path to a h5ad file to be modified changes Options: 1. A list of annotaions to be removed (separated by &quot;,&quot;) 2. A path to a csv file contains cell level annotations (first column is the cell ID) 3. A list of genes (separated by &quot;,&quot;, empty or max 50) to be exported along with all annotations. optional arguments: -h, --help show this help message and exit Powered by the Research Data Sciences Group [zhengyu.ouyang@biogen.com;yuhenry.sun@biogen.com] ------------ We use this pubic E-MTAB-11115 data as an example: 11.3.1 Remove annotations To remove annotation, we can simply pass the annotation header names to the program, and it will remove these headers, and re-write the original file. Please back-up the original file first if you would like to keep a copy ot it. As an example, here we remove the following headers: predicted.celltype2 and predicted.location. scTool rm ProjName_raw_added.h5ad predicted.celltype2,predicted.location 11.3.2 Add annotations To provide a new annotation, the user needs to prepare a csv file containing cell barcode and new annotation names. For example, we use the following csv file to include a manual.curated.labels cell type labeling to the original data: $ head -2 manual.curated.labels.csv AAACCCAAGGAAGTAG-1-5705STDY8058280,neurons AAACCCAAGGGCAGTT-1-5705STDY8058280,Oligos #Run the scTool: scTool add ProjName_raw_added.h5ad manual.curated.labels.csv 11.3.3 Export gene expressions This function exports gene expression values of provided genes, along with all other annotations. This provides a flexible way to examine the expression values of a set of genes. scTool export ProjName_raw_added.h5ad App,Olig1,P2ry12 The output result is a .csv file: ProjName_raw_added.h5ad.csv. Here is an example of the output file: 11.3.4 Demo scTool We use the h5ad file generated from demo data set to test scTool: scRNASequest_demo.h5ad. scTool export scRNASequest_demo.h5ad App,Olig1,P2ry12 The output will be a scRNASequest_demo.h5ad.csv file. "],["miscellaneous.html", "Chapter 12 Miscellaneous 12.1 Cell subsetting", " Chapter 12 Miscellaneous This section documents some use cases of this pipeline. 12.1 Cell subsetting This feature allows users to subset cells from an existing analysis and rerun the pipeline. The following solution takes advantage of the metapath column in the sampleMeta.csv file to subset the cell barcodes to be included in the analysis. To review the setting of the sampleMeta.csv file, please see the previous section here. Here are the steps: After the first round of analysis, a user can extract a subset of the cell ids along with some cell-level annotation (keep a record of how the subset is done) from h5ad/seruat, or on Cellxgene VIP (through heatmap getData). A user can then split the cell ids into each sample according to the prefix, and remove the prefix (cell id without the prefix to be the first column in the csv file). Add this cell-level annotation csv file into the metapath in the sample sheet for each sample. Then run scAnalyzer on this new sample sheet, the original data will be subsetted, and a message of how many cells were extracted for each sample will be on stdout. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
